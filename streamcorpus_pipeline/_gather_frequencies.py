'''gather term and document frequencies of tokens and mentions
generated by an NER transform.

.. This software is released under an MIT/X11 open source license.
   Copyright 2015 Diffeo, Inc.

'''

from __future__ import absolute_import
from collections import Counter
import itertools

from streamcorpus import OffsetType
from streamcorpus_pipeline._clean_visible import cleanse
from streamcorpus_pipeline.stages import Configured


class gather_frequencies(Configured):
    '''Gather term and document frequencies of tokens and mentions
    generated by an NER transform identified by `tagger_id`.

    '''
    config_name = 'gather_frequencies'
    def __init__(self, config):
        super(gather_frequencies, self).__init__(config)
        self.tagger_id = self.config['tagger_id']

    def __call__(self, si, context):
        if 'string_counts' not in context:
            context['string_counts'] = Counter()
        tagger_id = self.config['tagger_id']
        if not si.body.sentences or tagger_id not in si.body.sentences:
            return None
        sentences = si.body.sentences[tagger_id]
        tokens = list(itertools.chain(*[sent.tokens for sent in sentences]))

        def add_tokens(multitoken):
            full_str = ' '.join(multitoken)
            cleansed_string = cleanse(full_str.decode('utf8')).encode('utf8')
            if cleansed_string == '':
                return
            context['string_counts'][cleansed_string] += 1

            if len(multitoken) > 1:
                for tok in multitoken:
                    cleansed_token = cleanse(tok.decode('utf8')).encode('utf8')
                    if cleansed_token == '':
                        return
                    context['string_counts'][cleansed_token] += 1

        curr_mention_id = -1
        multitoken = []
        for tok in tokens:
            if tok.mention_id != curr_mention_id:
                add_tokens(multitoken)
                multitoken = [tok.token]
                curr_mention_id = tok.mention_id
            else:
                if curr_mention_id == -1:
                    add_tokens(multitoken)
                    multitoken = [tok.token]
                else:
                    multitoken.append(tok.token)
        if len(multitoken) > 0:
            add_tokens(multitoken)

        return si
